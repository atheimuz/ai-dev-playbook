---
title: "Claude Code 사용 성숙도 & 자기 분석 — 3단계 모델과 4축 스코어링"
description: "초보→중급→고급 성숙도 모델, 4축 100점 스코어링, 세션 분석 자동화, 1,425개 세션에서 배운 것들"
category: "팁"
tags: ["claude-code", "성숙도", "스코어링", "세션분석", "자기진단"]
date: "2026-02-17"
---

컨텍스트를 잘 관리하고 있는 건지, 토큰이 낭비되는 부분은 없는지, 자동화할 수 있는데 놓치고 있는 건 없는지.
내가 클로드 코드를 잘 활용하고 있는지에 대해 확인할 방법이 없었다.
1,425개 세션 로그를 분석하고 나서야 실제로 어디서 새고 있는지 보이기 시작했다.

## 3단계 성숙도 모델

### Level 1: 수동 (초보)

특징:

- Claude에게 직접 대화로 모든 걸 요청
- `/clear` 후 파일 수동 첨부 반복
- CLAUDE.md 없거나 기본적인 내용만
- 세션이 70-150턴씩 진행됨
- 후속 수정 빈도 높음

### Level 2: 도구 활용 (중급)

특징:

- CLAUDE.md에 프로젝트 규칙 정의
- 커스텀 스킬/커맨드 사용
- Plan Mode 활용
- 서브에이전트에 탐색 위임
- 세션이 30-50턴으로 줄어듦

### Level 3: 파이프라인 (고급)

특징:

- 오케스트레이터 커맨드로 전체 워크플로우 자동화
- 모델 배분 전략 (Opus/Sonnet/Haiku)
- 병렬 에이전트 실행
- 회고 루프로 셀프 개선
- 세션 분석으로 사용 패턴 모니터링

## 4축 100점 스코어링

세션의 효율성을 측정하는 4가지 축이다.

### 축 1: 의도 전달력 (25점)

요청이 얼마나 명확한지 평가한다.

| 점수  | 기준                             |
| ----- | -------------------------------- |
| 20-25 | 한번에 원하는 결과가 나오는 수준 |
| 15-19 | 대부분 명확하나 일부 모호        |
| 10-14 | 자주 재설명이 필요               |
| 0-9   | 대부분 모호해서 반복 수정        |

### 축 2: 작업 효율성 (30점)

배점이 가장 높다.
재수정 횟수가 토큰 비용과 시간에 직결되기 때문이다.

| 점수  | 기준             |
| ----- | ---------------- |
| 25-30 | 재수정 거의 없음 |
| 18-24 | 간헐적 재수정    |
| 10-17 | 빈번한 재수정    |
| 0-9   | 거의 매번 재수정 |

### 축 3: 도구 적합성 (25점)

상황에 맞는 도구를 선택했는지 평가한다.
탐색은 서브에이전트, 구현은 메인으로 분리하는 게 기준이다.

### 축 4: 워크플로우 성숙도 (20점)

스킬, 커맨드, Plan Mode, 회고 활용도를 평가한다.

### 총점 해석

| 총점   | 수준 | 다음 단계                  |
| ------ | ---- | -------------------------- |
| 80-100 | 고급 | 파이프라인 최적화, 팀 공유 |
| 60-79  | 중급 | 서브에이전트, 커맨드 도입  |
| 40-59  | 초급 | CLAUDE.md, Plan Mode 시작  |
| 0-39   | 입문 | 기본 사용법 학습           |

## 세션 분석 자동화

`/session-analyzer` 스킬로 세션 로그를 자동 분석한다.

동작 방식:

1. 날짜 범위 질문 (오늘/어제/7일/전체)
2. JSONL 세션 로그를 Python 스크립트로 분석
3. 스킬/커맨드/에이전트 동적 수집 (하드코딩 없음)
4. 4축 스코어링 결과 생성

리포트 예시:

```markdown
# 세션 분석 리포트 — 2026-02-15

## 요약

- 분석 세션 수: 5
- 평균 턴 수: 38
- 총 스코어: 78/100

## 개선 포인트

- 코드베이스 탐색을 메인에서 직접 수행한 경우 3건
  → Explore 에이전트에 위임하면 컨텍스트 절약
```

보안 규칙: 프로젝트명, 파일 경로, 코드 내용은 리포트에 포함하지 않는다.

## 자기 진단 체크리스트

### Level 1 → Level 2

- [ ] CLAUDE.md에 프로젝트 규칙을 5개 이상 정의했는가
- [ ] Plan Mode를 구현 전에 사용하는가
- [ ] 세션당 턴 수를 50 이하로 유지하는가
- [ ] 서브에이전트에 탐색을 위임하는가

### Level 2 → Level 3

- [ ] 커스텀 커맨드(오케스트레이터)를 만들었는가
- [ ] 서브에이전트에 모델을 역할별로 다르게 배분하는가
- [ ] `/retrospective`로 정기적으로 회고하는가
- [ ] CLAUDE.md가 회고를 통해 계속 개선되는가

## 1,425개 세션에서 배운 것들

~/.claude/projects/ 아래 1,425개 JSONL 세션 로그에서 반복적으로 나타난 패턴들이다.

**세션 길이와 품질:**

- 30-50턴: 후속 수정 0-1회, 최적 구간
- 50-70턴: 후속 수정 증가 시작
- 70턴 이상: 후속 수정 1.5-2배, 품질 저하

**Plan Mode 사용 여부:**

| 지표       | Plan 없이 | Plan 사용 시 |
| ---------- | --------- | ------------ |
| 후속 수정  | 1.5-2배   | 0-1회        |
| 세션 턴 수 | 70-150    | 30-50        |

**731개 디버그 로그에서 발견한 문제:**

1. 서브에이전트 컨텍스트 단절 — 가장 빈번, code-analyst로 해결
2. 토큰 초과 세션 중단 — 50턴 규칙과 `/compact`로 대응
3. Plan Mode에서 코드 작성 — CLAUDE.md 규칙 추가로 해결
4. 서브에이전트 파일 경로 오류 — implementation-guide.md에 정확한 경로 명시

## 돌아보며

성숙도 모델을 만들기 전에는 "잘 쓰고 있는 것 같다"는 감각에만 의존했다.
78점에서 85점으로 올랐다는 숫자가 생기니까 뭘 개선해야 할지가 보였다.

1,425개 세션의 결론은 단순하다.
50턴 넘기지 말고, Plan 먼저 쓰고, 서브에이전트에 탐색을 맡기고, 회고를 해라.
이 네 가지만 지켜도 수준이 많이 올라간다.
